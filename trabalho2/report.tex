\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage[portuges,brazil,english]{babel}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage[ruled,vlined,linesnumbered,portuguese]{algorithm2e}
\usepackage[utf8]{inputenc}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Trabalho 1 - MC886 Aprendizado de Máquina}

\author{\IEEEauthorblockN{Leo Yuuki Omori Omi}
\IEEEauthorblockA{
138684 \\
leoyuuki@gmail.com}
\and
\IEEEauthorblockN{João Pedro Ramos Lopes}
\IEEEauthorblockA{
139546 \\
jpedrorl@gmail.com}}

\maketitle

\section{Introdução}


Neste trabalho, temos o objetivo de explorar as técnicas de classificação vistas em aula para construir um sistema de reconhecimento de objetos para classificar imagens. Utilizando a Regressão Logística e Redes Neurais, iremos construir vários modelos para classificar imagens do conjunto de dados CIFAR-10.

\section{Regressão Logística}
 
A regressão logística é um método utilizado em Aprendizado de Máquina para classificação. Este método utiliza a função sigmóide para predizer se uma entrada é de um determinado conjunto ou não, ou seja é classificação binária.
Em casos de classificação de múltiplas classes, temos duas abordagens que foram utilizadas neste trabalho.
A abordagem Um-Contra-Todos (\textit{One-vs-All}) calcula a probabilidade estimada de cada uma das classes contra todas outras, escolhendo aquela classe que maximiza esta probabilidade.
A abordagem multinomial utiliza a função \textit{Softmax}, dando a entrada uma probabilidade para esta entrada uma probabilidade para todas as classes.

\section{Soluções Propostas}

\subsection{Solução Base (One vs All)}
A primeira solução proposta foi aplicar a regressão linear usando a classificação de múltiplas class Um-contra-todos os níveis de cinza de cada pixel da imagem (foi utilizada a função rgb2gray do Scikit-image). Foi utilizado a implementação de Regressão Logística do Scikit-learn, sendo que o parâmetro multi\_class foi setado para \'ovr\'.

\subsection{Solução Base Melhorada}
Para analisar possíveis jeitos de melhorar o modelo, foram realizados três experimentos com o objetivo de melhorar a solução base. O primeiro foi utilizar um operador de bordas nas imagens e depois realizar a regressão logística. Foi utilizado o operador de Roberts implementado no Scikit-image. O segundo exprimento foi realizar uma segmentação da imagem e aplicar a regressão logística. A segmentação foi implementada utlizando a função de Otsu para obter uma limiar para cada imagem e criar uma máscara na imagem com o intuito de isolar o objeto do plano de fundo. O terceiro experimento foi utilizar a Análise de Compenentes Principais ou \textit{Principal Component Analysis} para reduzir a dimensionalidade do modelo, utilizando a implementação do Scikit-learn.

\subsection{Solução Base (Multinomial)}
Esta solução utiliza a Regressão Logística Multinomial, utilizando o melhor resultado entre os experimentos anteriores (níveis de cinza, operador de bordas ou segmentação). Para esta solução utilizamos a implementação de Regressão Logística do Scikit-learn, com o parâmetro multi\_class setado para \'multinomial\' e o parâmetro solver setado para \'sag\' (\textit{Stochastic Gradient Descent}).

\section{Experimentos}
\subsection{Modelos iniciais}
Para o modelo base e de múltiplos graus de regressão logística, utilizamos de \textit{k-fold cross-validation}, com k=5 conjuntos, para verificarmos o funcionamento dos modelos. Para os experimentos, utilizamos estes conjuntos de dados para que pudéssemos ver a acurácia (utlizando a função \textit{score} do scikit-learn) do conjunto de treino e do conjunto de validação para verificarmos se houve \textit{overfitting} (ou \textit{underfitting}). Então calculamos a média aritmética dos resultados para o conjunto de testes e validação.

\subsubsection{Solução Base (One vs All)}
A solução base que utiliza como \textit{features} os níveis de cinza de todos os pixels da imagem obteve uma acurácia para o conjunto de testes de 35\% e para o de validação 28\%. A diferença de 7\% entre a acurárcia dos dois conjuntos indica que houve um pouco de \textit{overfitting} neste caso, e além disso, obtivemos um resultado pouco satisfatório.
}
\subsubsection{Solução Base Melhorada}
Com o intuito de de melhorar a solução base, foram feitos experimentos utilizando funções de borda e de segmentação. A solução de função de borda trouxe resultados na média muito próximos à solução original. Poderíamos concluir à partir deste resultado, que a extração de bordas da imagem não extrai dados que sejam relevantes para a melhora do modelo, e é algo que a própria regressão logística sobre os valores de cinza da imagem original acaba considerando de certa maneira. A segunda solução utilizando a segmentação obteve resultados piores de acurácia. 30\% para o conjunto de testes e 21\% no conjunto de validação. A causa desta queda pode ser atribuído à técnica simples da segmentação, já que em alguns casos a máscara pode extrair o objeto da imagem e em outros o plano de fundo, dependendo dos níveis de cinza do objeto serem maiores ou menores que o do fundo. Portanto, não obtivemos melhoras significativas com estas soluções, portanto iremos utlizar os níveis de cinza como na primeira solução proposta para as próximas soluções do trabalho.

\subsubsection{Solução Base PCA}
Foi utilizada a Análise de Compenentes Principais com vários valores de k.

\subsection{Solução Base (Multinomial)}
Para esta solução obtivemos também uma acurácia de 35\% para o conjunto de testes e 28\% para o de validação. Nota-se que o algoritmo de descida de gradiente estocástica não chegou a convergir e parou pelo número de iterações máximo ter sido atingido. Como para todos as soluções utlizando Regressão Linear obtivemos praticamente a mesma acurácia, poderíamos concluir que talvez este método não seja o mais adequado ao problema, ou que os dados da maneira que foram utilizados não era adequados para o modelo.


\section{Conclusões}
Sobre os modelos baseados em gradientes, é notável a velocidade de convergência, principalmente no modelo estocástico que obtém erro baixo nas primeiras 5 iterações. Por outro lado, esses modelos necessitam de um fino ajuste da taxa de aprendizado.

É importante apontar que o algoritmo com melhor desempenho final, baseado na meta-heurística de Algoritmos Genéticos, usualmente não é utilizadp para casos contínuos, mas obteve uma boa solução apesar do relativo alto custo de tempo. 

Também é importante notar que os o modelo de GA obteve melhor desempenho para anos com maior número de exemplares do conjunto (próximos do ano 2000), enquanto os outros dois modelos obtiveram melhores desempenhos para anos com um menor número de dados. Esse fato deve ser investigado em trabalhos futuros, visando a encontrar o que levou ao baixo desempenho de modelos comumente aplicados na resolução do problema de Regressão Linear.  


\begin{thebibliography}{00}
\bibitem{linearregression1} Montgomery, D.C., Peck, E.A. and Vining, G.G., 2015. Introduction to linear regression analysis. John Wiley \& Sons.
\bibitem{gendreau2010handbook} Gendreau, M. and Potvin, J.Y., 2010. Handbook of metaheuristics (Vol. 2). New York: Springer.
\bibitem{continousgenetics} Haupt, R.L. and Haupt, S.E., 2004. Practical genetic algorithms. John Wiley \& Sons.
\bibitem{continuousgenetics2} Djurisic, A.B., Elazar, J.M. and Rakic, A.D., 1997. Genetic algorithms for continuous optimization problems-a concept of parameter-space size adjustment. Journal of Physics A: Mathematical and General, 30(22), p.7849.
\end{thebibliography}

\end{document}
