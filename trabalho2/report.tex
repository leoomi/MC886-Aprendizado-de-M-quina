\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage[portuges,brazil,english]{babel}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage[export]{adjustbox}
\usepackage{float}
\usepackage[ruled,vlined,linesnumbered,portuguese]{algorithm2e}
\usepackage[utf8]{inputenc}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Trabalho 1 - MC886 Aprendizado de Máquina}

\author{\IEEEauthorblockN{Leo Yuuki Omori Omi}
\IEEEauthorblockA{
138684 \\
leoyuuki@gmail.com}
\and
\IEEEauthorblockN{João Pedro Ramos Lopes}
\IEEEauthorblockA{
139546 \\
jpedrorl@gmail.com}}

\maketitle

\section{Introdução}


Neste trabalho, temos o objetivo de explorar as técnicas de classificação vistas em aula para construir um sistema de reconhecimento de objetos para classificar imagens. Utilizando a Regressão Logística e Redes Neurais, iremos construir vários modelos para classificar imagens do conjunto de dados CIFAR-10.

\section{Regressão Logística}
 
A regressão logística é um método utilizado em Aprendizado de Máquina para classificação. Este método utiliza a função sigmóide para predizer se uma entrada é de um determinado conjunto ou não, ou seja é classificação binária.
Em casos de classificação de múltiplas classes, temos duas abordagens que foram utilizadas neste trabalho.
A abordagem Um-Contra-Todos (\textit{One-vs-All}) calcula a probabilidade estimada de cada uma das classes contra todas outras, escolhendo aquela classe que maximiza esta probabilidade.
A abordagem multinomial utiliza a função \textit{Softmax}, dando a entrada uma probabilidade para esta entrada uma probabilidade para todas as classes.

\section{Soluções Propostas}

\subsection{Solução Base (One vs All)}
A primeira solução proposta foi aplicar a regressão linear usando a classificação de múltiplas class Um-contra-todos os níveis de cinza de cada pixel da imagem (foi utilizada a função rgb2gray do Scikit-image). Foi utilizado a implementação de Regressão Logística do Scikit-learn, sendo que o parâmetro multi\_class foi setado para \'ovr\'.

\subsection{Solução Base Melhorada}
Para analisar possíveis jeitos de melhorar o modelo, foram realizados três experimentos com o objetivo de melhorar a solução base. O primeiro foi utilizar um operador de bordas nas imagens e depois realizar a regressão logística. Foi utilizado o operador de Roberts implementado no Scikit-image. O segundo exprimento foi realizar uma segmentação da imagem e aplicar a regressão logística. A segmentação foi implementada utlizando a função de Otsu para obter uma limiar para cada imagem e criar uma máscara na imagem com o intuito de isolar o objeto do plano de fundo. O terceiro experimento foi utilizar a Análise de Compenentes Principais ou \textit{Principal Component Analysis} para reduzir a dimensionalidade do modelo, utilizando a implementação do Scikit-learn.

\subsection{Solução Base (Multinomial)}
Esta solução utiliza a Regressão Logística Multinomial, utilizando o melhor resultado entre os experimentos anteriores (níveis de cinza, operador de bordas, segmentação ou PCA). Para esta solução utilizamos a implementação de Regressão Logística do Scikit-learn, com o parâmetro multi\_class setado para \'multinomial\' e o parâmetro solver setado para \'sag\' (\textit{Stochastic Gradient Descent}).

\section{Experimentos}
\subsection{Modelos iniciais}
Para o modelo base e de múltiplos graus de regressão logística, utilizamos de \textit{k-fold cross-validation}, com k=5 conjuntos, para verificarmos o funcionamento dos modelos. Para os experimentos, utilizamos estes conjuntos de dados para que pudéssemos ver a acurácia (utlizando a função \textit{score} do scikit-learn) do conjunto de treino e do conjunto de validação para verificarmos se houve \textit{overfitting} (ou \textit{underfitting}). Então calculamos a média aritmética dos resultados para o conjunto de testes e validação.

\subsubsection{Solução Base (One vs All)}
A solução base que utiliza como \textit{features} os níveis de cinza de todos os pixels da imagem obteve uma acurácia para o conjunto de testes de 35\% e para o de validação 28\%. A diferença de 7\% entre a acurárcia dos dois conjuntos indica que houve um pouco de \textit{overfitting} neste caso, e além disso, obtivemos um resultado pouco satisfatório.
}
\subsubsection{Solução Base Melhorada}
Com o intuito de de melhorar a solução base, foram feitos experimentos utilizando funções de borda e de segmentação. A solução de função de borda trouxe resultados na média muito próximos à solução original. Poderíamos concluir à partir deste resultado, que a extração de bordas da imagem não extrai dados que sejam relevantes para a melhora do modelo, e é algo que a própria regressão logística sobre os valores de cinza da imagem original acaba considerando de certa maneira.

\begin{figure}[H]
  \includegraphics[center]{bor.png}
  \caption{Operador de borda}
  \label{fig:frog1}
\end{figure}

A segunda solução utilizando a segmentação obteve resultados piores de acurácia. 30\% para o conjunto de testes e 21\% no conjunto de validação. A causa desta queda pode ser atribuído à técnica simples da segmentação, já que em alguns casos a máscara pode extrair o objeto da imagem e em outros o plano de fundo, dependendo dos níveis de cinza do objeto serem maiores ou menores que o do fundo. Portanto, não obtivemos melhoras significativas com estas soluções, portanto iremos utlizar os níveis de cinza como na primeira solução proposta para as próximas soluções do trabalho.

\begin{figure}[H]
  \includegraphics[center]{seg1.png}
  \caption{Segmentação isolando o plano de fundo}
  \label{fig:boat1}
\end{figure}

\begin{figure}[H]
  \includegraphics[center]{seg2.png}
  \caption{Segmentação isolando o objeto}
  \label{fig:frog1}
\end{figure}

\subsubsection{Solução Base PCA}
A solução utilizando o PCA, deu resultados bons. Foi escrito um programa rodando em um laço com valores crescentes para o número de compenentes, começando com 15 componentes e aumentando em 16 em cada iteração. A execução do problema é lenta, mas nos trouxe resultados que puderam ser aproveitados. Por volta de 40 componentes, obtemos uma acurácia de 30\% tanto para o conjunto de treino como o conjunto de validação, o que foi o melhor resultado observado utilizando a regressão logística. Como obtemos uma acurácia semelhante entre os dois conjuntos, poderíamos dizer que não está ocorrendo \textit{overfitting}, diferente das soluções anteriores. Além disso, como diminuímos a dimensionalidade do modelo, obtemos uma solução computacionalmente mais leve.

\begin{table}[H]
\centering
\caption{Tabela de acurácia por número de componentes}
\label{my-label}
\begin{tabular}{lllll}
Componentes & Acurácia Treino & Acurácia Validação & & \\
15  & 0.29 & 0.29 &  &  \\
31  & 0.3  & 0.3  &  &  \\
47  & 0.3  & 0.3  &  &  \\
63  & 0.31 & 0.3  &  &  \\
79  & 0.31 & 0.3  &  &  \\
95  & 0.31 & 0.3  &  &  \\
111 & 0.31 & 0.3  &  &  \\
127 & 0.31 & 0.3  &  &  \\
143 & 0.32 & 0.3  &  &  \\
159 & 0.32 & 0.3  &  &  \\
175 & 0.32 & 0.3  &  &  \\
191 & 0.32 & 0.3  &  &  \\
207 & 0.32 & 0.3  &  &  \\
223 & 0.32 & 0.3  &  &  \\
239 & 0.32 & 0.3  &  &  \\
255 & 0.32 & 0.3  &  &  \\
271 & 0.32 & 0.29 &  &  \\
287 & 0.32 & 0.29 &  &  \\
303 & 0.32 & 0.29 &  &  \\
319 & 0.32 & 0.29 &  &  \\
335 & 0.32 & 0.29 &  &  \\
351 & 0.33 & 0.29 &  &  \\
367 & 0.33 & 0.29 &  &  \\
383 & 0.33 & 0.29 &  &  \\
399 & 0.33 & 0.29 &  &  \\
415 & 0.33 & 0.29 &  & 
\end{tabular}
\end{table}

\subsection{Solução Base (Multinomial)}
Para esta solução, usando a regressão multinomial com PCA, obtivemos também uma acurácia de 30\% para o conjunto de testes e 30\% para o de validação. Um resultado semelhantes ao do One vs All, não obtendo uma melhora o resultado em comparação com a solução anterior.

\section{Conclusões}
Sobre as soluções propostas, aquelas que se utilizaram de processamento de imagem não trouxeram melhoras para o modelo. No entanto, a solução utilizando PCA trouxe melhoras tanto para o resultado quanto para tempo de computação do modelo, demonstrando a vantagem de usar a redução de dimensionalidade por este método.

\begin{thebibliography}{00}
\bibitem{linearregression1} Montgomery, D.C., Peck, E.A. and Vining, G.G., 2015. Introduction to linear regression analysis. John Wiley \& Sons.
\bibitem{gendreau2010handbook} Gendreau, M. and Potvin, J.Y., 2010. Handbook of metaheuristics (Vol. 2). New York: Springer.
\bibitem{continousgenetics} Haupt, R.L. and Haupt, S.E., 2004. Practical genetic algorithms. John Wiley \& Sons.
\bibitem{continuousgenetics2} Djurisic, A.B., Elazar, J.M. and Rakic, A.D., 1997. Genetic algorithms for continuous optimization problems-a concept of parameter-space size adjustment. Journal of Physics A: Mathematical and General, 30(22), p.7849.
\end{thebibliography}

\end{document}
